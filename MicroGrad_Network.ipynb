{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2c3ddcd",
   "metadata": {},
   "source": [
    "##### → Import Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f2560d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.6.0+cpu.\n",
      "NumPy Version: 2.1.3.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from graphviz import Digraph\n",
    "from graphviz import Source\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "print(f'PyTorch Version: {torch.__version__}.')\n",
    "print(f'NumPy Version: {np.__version__}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf04351",
   "metadata": {},
   "source": [
    "##### → Design Data Structure and Computational Graph: how does a node look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3bc8288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "    def __init__(self, data, _children=[], _operation='', label=''):\n",
    "        self.data = data\n",
    "        self.grad = 0.0    # No effect when an instance (=object) has been just created.\n",
    "        self.label = label\n",
    "\n",
    "        # These are for backprop.\n",
    "        self._children = _children\n",
    "        self._operation = _operation\n",
    "        self._backward = lambda: None # blank function.\n",
    "        '''\n",
    "        • The left nodes cannot call not  _backward method.\n",
    "        • It is an empty function when an instance (=object) has just been created.\n",
    "        • \"def v(): None\" and \"v = lambda: None\" represent exactly same function.\n",
    "        '''\n",
    "    #end-def\n",
    "\n",
    "    def __repr__(self,):\n",
    "        return f'Value(data={self.data:0.4f}, grad={self.grad:0.4f}, label={self.label})'\n",
    "    #end-def\n",
    "\n",
    "    def __add__(self, other):\n",
    "        '''\n",
    "        • Operation: When we ask to calculate \"a+b,\" \n",
    "        Python internally calls \"a.__add__(b).\"\n",
    "        '''\n",
    "        other = other if isinstance(other, Value) else Value(data=other)\n",
    "        \n",
    "        output = Value(data=self.data + other.data,\n",
    "                     _children=[self, other],\n",
    "                     _operation='+')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad  += 1.0 * output.grad\n",
    "            other.grad += 1.0 * output.grad\n",
    "        #end-def\n",
    "        output._backward = _backward\n",
    "        # This should not be _backward(); otherwise, it calls each time.\n",
    "        return output\n",
    "    #end-def\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        return self + other\n",
    "    #end-def\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        '''\n",
    "        Operation: When we ask to calculate \"a*b,\" \n",
    "        Python internally calls \"a.__mul__(b).\"\n",
    "        '''\n",
    "        other = other if isinstance(other, Value) else Value(data=other)\n",
    "\n",
    "        output = Value(data=self.data * other.data,\n",
    "                     _children=[self, other],\n",
    "                     _operation='*')\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad  += other.data * output.grad\n",
    "            other.grad += self.data  * output.grad\n",
    "\n",
    "            # print(f'''\n",
    "            #     self.data: {self.data}, self.grad: {self.grad},\n",
    "            #     other.data: {other.data}, self.grad: {other.grad}, \n",
    "            #     output.data: {output.data}, output.grad {output.grad}\n",
    "            # ''')\n",
    "        #end-def\n",
    "        output._backward = _backward\n",
    "        # This should not be _backward(); otherwise, it calls each time.\n",
    "        return output\n",
    "    #end-def\n",
    "\n",
    "    def __rmul__(self, other):\n",
    "        return self * other\n",
    "    #end-def\n",
    "\n",
    "    def __neg__(self):\n",
    "        return self * (-1.0)\n",
    "    #end-def\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        return self + (-other)\n",
    "    #end-def\n",
    "\n",
    "    def __rsub__(self, other):\n",
    "        return (-self) + other\n",
    "    #end-def\n",
    "\n",
    "    def __pow__(self, other):\n",
    "        assert isinstance(other, (int, float)), '__pow__ supports solely int and float.'\n",
    "        \n",
    "        output = Value(self.data ** other, _children=[self,], _operation=f'{self.data}^{other}')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += (other * (self.data ** (other - 1.0))) * output.grad\n",
    "        #end-def\n",
    "        output._backward = _backward\n",
    "        \n",
    "        return output\n",
    "    #end-def\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        # z = a(=2) / 2.5 = 0.8\n",
    "        return self * (other ** (-1.0))\n",
    "    #end-def\n",
    "\n",
    "    def __rtruediv__(self, other):\n",
    "        # z = 2.5 / a(=2) = 1.25\n",
    "        return (self**(-1.0)) * other\n",
    "\n",
    "    def tanh(self):\n",
    "        x = self.data\n",
    "        \n",
    "        # exponent_portion = math.exp(2.0*x) # exponet_portion = (2.0*x).exp()\n",
    "\n",
    "        # data = (exponent_portion - 1) / (exponent_portion + 1)\n",
    "\n",
    "        data = math.tanh(x)\n",
    "\n",
    "        output = Value(data=data, _children=[self], _operation='tanh( )')\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad += (1.0-(output.data**2.0)) * output.grad\n",
    "        #end-def\n",
    "        output._backward = _backward\n",
    "\n",
    "        return output\n",
    "    #end-def\n",
    "\n",
    "    def ReLU(self):\n",
    "        x = self.data\n",
    "        output = Value(data=x if x>0 else 0.0, _children=[self,], _operation='ReLU( )')\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad += (1.0 if x>0 else 0.0) * output.grad\n",
    "        #end-def\n",
    "        output._backward = _backward\n",
    "        \n",
    "        return output\n",
    "    #end-def\n",
    "\n",
    "    def log(self):\n",
    "        output = Value(data=math.log(self.data), _children=[self,], _operation='logₑ( )')\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad += (1.0/self.data) * output.grad\n",
    "        #end-def\n",
    "        output._backward = _backward\n",
    "        \n",
    "        return output\n",
    "    #end-def\n",
    "\n",
    "    def sigmoid(self):\n",
    "        x = self.data\n",
    "        \n",
    "        sigmoid = 1.0 / (1.0 + math.exp(-x))\n",
    "\n",
    "        output = Value(data=sigmoid, _children=[self,], _operation='sigmoid( )')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += (sigmoid * (1.0 - sigmoid)) * output.grad\n",
    "        #end-def\n",
    "\n",
    "        output._backward = _backward\n",
    "        return output\n",
    "    #end-def\n",
    "\n",
    "    def exp(self,):\n",
    "        x = math.exp(self.data)\n",
    "        output = Value(data=x, _children=[self,], _operation='exp( )')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += x * output.grad\n",
    "        #end-def\n",
    "        output._backward = _backward\n",
    "        return output\n",
    "    #end-def\n",
    "\n",
    "    def backward(self):\n",
    "        ordered_topology = []\n",
    "        visited_nodes = []\n",
    "\n",
    "        def build_topology(node):\n",
    "            if node not in visited_nodes:\n",
    "                visited_nodes.append(node)\n",
    "\n",
    "                # children = node._children\n",
    "                # child = 0\n",
    "                # while child<len(children):\n",
    "                #     build_topology(children[child])\n",
    "                #     child += 1\n",
    "                # #end-while\n",
    "\n",
    "                for child in node._children:\n",
    "                    build_topology(child)\n",
    "                #end-for\n",
    "                \n",
    "                ordered_topology.append(node)\n",
    "            #end-if/else\n",
    "        #end-def\n",
    "        build_topology(self)\n",
    "\n",
    "        self.grad = 1.0\n",
    "        for node in reversed(ordered_topology):\n",
    "            node._backward()\n",
    "        #end-def\n",
    "    #end-def\n",
    "#end-def"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75357646",
   "metadata": {},
   "source": [
    "##### → Lookup the Computational Graph: connect_dot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c8e3965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace(root):\n",
    "    # builds a set of all nodes and edges in a graph\n",
    "    nodes, edges = set(), set()\n",
    "    def build(v):\n",
    "        if v not in nodes:\n",
    "            nodes.add(v)\n",
    "            for child in v._children:\n",
    "                edges.add((child, v))\n",
    "                build(child)\n",
    "            #end-for\n",
    "        #end-if/else\n",
    "    #end-def\n",
    "    build(root)\n",
    "    return nodes, edges\n",
    "#end-def\n",
    "\n",
    "def connect_dot(root):\n",
    "    dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'}) # LR = left to right\n",
    "\n",
    "    nodes, edges = trace(root)\n",
    "    for n in nodes:\n",
    "        uid = str(id(n))\n",
    "        # for any value in the graph, create a rectangular ('record') node for it\n",
    "        dot.node(name = uid, label = \"%s | {data = %.4f} | {grad = %.4f}\" % (n.label, n.data, n.grad), shape='record')\n",
    "        if n._operation:\n",
    "            # if this value is a result of some operation, create an op node for it\n",
    "            dot.node(name = uid + n._operation, label = n._operation)\n",
    "            # and connect this node to it\n",
    "            dot.edge(uid + n._operation, uid)\n",
    "        #end-else/if\n",
    "    #end-for\n",
    "\n",
    "    for n1, n2 in edges:\n",
    "        # connect n1 to the op node of n2\n",
    "        dot.edge(str(id(n1)), str(id(n2)) + n2._operation)\n",
    "    #end-for\n",
    "\n",
    "    return dot\n",
    "#end-def"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba7fa8d",
   "metadata": {},
   "source": [
    "##### // Test Backprop on Computational Graph / Test Engine: MicroGrad vs PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b44aa476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_1():\n",
    "    x = Value(-4.0)\n",
    "    z = 2 * x + 2 + x\n",
    "    q = z.ReLU() + z * x\n",
    "    h = (z * z).ReLU()\n",
    "    y = h + q + q * x\n",
    "    y.backward()\n",
    "    x_mg, y_mg = x, y\n",
    "\n",
    "    # Value(data=-4.0000, grad=46.0000, label=) Value(data=-20.0000, grad=1.0000, label=)\n",
    "    # print(x_mg.data, y_mg.data)\n",
    "\n",
    "    x = torch.tensor([-4.0], requires_grad = True)\n",
    "    z = 2 * x + 2 + x\n",
    "    q = z.relu() + z * x\n",
    "    h = (z * z).relu()\n",
    "    y = h + q + q * x\n",
    "    y.backward()\n",
    "    x_pt, y_pt = x, y\n",
    "\n",
    "    # tensor([-4.], requires_grad=True) tensor([-20.], grad_fn=<AddBackward0>)\n",
    "    # print(x_pt.data.item(), y_pt.data.item())\n",
    "\n",
    "    # Forward pass went well, if it works.\n",
    "    assert y_mg.data == y_pt.data.item()\n",
    "    # Backward pass went well, if it works.\n",
    "    assert x_mg.grad == x_pt.grad.item()\n",
    "#end-def\n",
    "\n",
    "sanity_check_1()\n",
    "\n",
    "\n",
    "\n",
    "def sanity_check_2():\n",
    "    a = Value(-4.0)\n",
    "    b = Value(2.0)\n",
    "    c = a + b\n",
    "    d = a * b + b**3\n",
    "    c += c + 1\n",
    "    c += 1 + c + (-a)\n",
    "    d += d * 2 + (b + a).ReLU()\n",
    "    d += 3 * d + (b - a).ReLU()\n",
    "    e = c - d\n",
    "    f = e**2\n",
    "    g = f / 2.0\n",
    "    g += 10.0 / f\n",
    "    g.backward()\n",
    "    a_mg, b_mg, g_mg = a, b, g\n",
    "\n",
    "    a = torch.tensor([-4.0], requires_grad = True)\n",
    "    b = torch.tensor([2.0],  requires_grad = True)\n",
    "    c = a + b\n",
    "    d = a * b + b**3\n",
    "    c = c + c + 1\n",
    "    c = c + 1 + c + (-a)\n",
    "    d = d + d * 2 + (b + a).relu()\n",
    "    d = d + 3 * d + (b - a).relu()\n",
    "    e = c - d\n",
    "    f = e**2\n",
    "    g = f / 2.0\n",
    "    g = g + 10.0 / f\n",
    "    g.backward()\n",
    "    a_pt, b_pt, g_pt = a, b, g\n",
    "\n",
    "    # Forward pass went well, if it works.\n",
    "    # print(g_mg.data, g_pt.data.item())\n",
    "    assert abs(g_mg.data == g_pt.data.item()) < (1/1000)\n",
    "    \n",
    "\n",
    "    # backward pass went well:\n",
    "    assert abs(a_mg.grad == a_pt.grad.item()) < (1/1000)\n",
    "    assert abs(b_mg.grad == b_pt.grad.item()) < (1/1000)\n",
    "#end-def\n",
    "\n",
    "sanity_check_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d042e",
   "metadata": {},
   "source": [
    "##### // Check MicroGrad_Engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15631cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"409pt\" height=\"78pt\"\n",
       " viewBox=\"0.00 0.00 409.19 78.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 74)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-74 405.19,-74 405.19,4 -4,4\"/>\n",
       "<!-- 132855580913424 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>132855580913424</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"278.19,-0.5 278.19,-69.5 401.19,-69.5 401.19,-0.5 278.19,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"339.69\" y=\"-54.3\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"278.19,-46.5 401.19,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"339.69\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.9866</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"278.19,-23.5 401.19,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"339.69\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">grad = 1.0000</text>\n",
       "</g>\n",
       "<!-- 132855580913424tanh( ) -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>132855580913424tanh( )</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"200.6\" cy=\"-35\" rx=\"41.69\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"200.6\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">tanh( )</text>\n",
       "</g>\n",
       "<!-- 132855580913424tanh( )&#45;&gt;132855580913424 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>132855580913424tanh( )&#45;&gt;132855580913424</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M242.36,-35C250.41,-35 259.09,-35 267.81,-35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"268.04,-38.5 278.04,-35 268.04,-31.5 268.04,-38.5\"/>\n",
       "</g>\n",
       "<!-- 132855580903568 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>132855580903568</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-0.5 0,-69.5 123,-69.5 123,-0.5 0,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"61.5\" y=\"-54.3\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-46.5 123,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"61.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;2.5000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-23.5 123,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"61.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">grad = 0.0266</text>\n",
       "</g>\n",
       "<!-- 132855580903568&#45;&gt;132855580913424tanh( ) -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>132855580903568&#45;&gt;132855580913424tanh( )</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123.03,-35C131.5,-35 140.14,-35 148.42,-35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"148.67,-38.5 158.67,-35 148.67,-31.5 148.67,-38.5\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x78d4d9b4ef50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Value(-2.5, label='a')\n",
    "\n",
    "z = a.tanh()\n",
    "\n",
    "# print(z)\n",
    "z.backward()\n",
    "connect_dot(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd97c9f",
   "metadata": {},
   "source": [
    "##### → Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ef3e977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def zero_grad(self):\n",
    "        for parameter in self.parameters():\n",
    "            parameter.grad = 0.0\n",
    "        #end-for\n",
    "    #end-def\n",
    "    def parameters(self):\n",
    "        return []\n",
    "    #end-def\n",
    "#end-class\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, nin: int, non_linearity=True):\n",
    "        # nin   [number_of_connections_of_each_neuron, number_of_dimenstions]: 3\n",
    "        # 'nin' indicates how many input(s) are connected to a [single] neuron.\n",
    "\n",
    "        self.weights       = [Value(data=random.uniform(-1, 1.0) * (nin**(-0.5)), label=f'w{_+1}') for _ in range(nin)]  # Value(data=[-1, 1))\n",
    "        self.b             = Value(data=0.0, label='b')\n",
    "        self.non_linearity = non_linearity\n",
    "    #end-def\n",
    "    \n",
    "    def __call__(self, xs):\n",
    "        # z = Σ(w[i] * x[i]) + b\n",
    "        # a = f(z)\n",
    "        \n",
    "        z = sum([(w*x) for w, x in zip(self.weights, xs)]) + self.b # pre-activation\n",
    "        # a = z.tanh() # passed through activaton function (=non linearity).\n",
    "        # a.label = 'a (=output for each sample)'\n",
    "        return z.ReLU() if self.non_linearity == True else z\n",
    "    #end-def\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.weights + [self.b]\n",
    "    #end-def\n",
    "#end-class\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    '''In a layer, every neuron is connected to inputs (nin), but \n",
    "    no neuron is connected to each other.'''\n",
    "    def __init__(self, nin: int, nout: int, non_linearity):\n",
    "        # nin   [number_of_connections_of_each_neuron, number_of_dimenstions]: 3\n",
    "        # nout  [number_of_neurons_of_each_layer]: 5\n",
    "        # nouts [neurons_of_each_layer]: [4, 4, 1]\n",
    "\n",
    "        self.neurons = [Neuron(nin, non_linearity) for _ in range(nout)]\n",
    "    #end-def\n",
    "\n",
    "    def __call__(self, xs):\n",
    "        outputs = [neuron(xs) for neuron in self.neurons]\n",
    "        return outputs if len(outputs) != 1 else outputs[0]\n",
    "    #end-def\n",
    "\n",
    "    def parameters(self):\n",
    "        # params = [neuron.parameters() for p in neuron for neuron in self.neurons]\n",
    "        # return params\n",
    "        # def parameters(self):\n",
    "            # return self.weights + [self.b]\n",
    "        # params = []\n",
    "        # for neuron in self.neurons:\n",
    "        #     for parameter in neuron.parameters():\n",
    "        #         params.append(parameter)\n",
    "        #     #end-for\n",
    "        # #end\n",
    "        return [parameter for neuron in self.neurons for parameter in neuron.parameters()]\n",
    "    #end-def\n",
    "#end-class\n",
    "\n",
    "\n",
    "class MLP(Module):\n",
    "    def __init__(self, nin, nouts):\n",
    "        # nin   [number_of_connections_of_each_neuron, number_of_dimenstions]: 3\n",
    "        # nout  [number_of_neurons_of_each_layer]: 5\n",
    "        # nouts [neurons_of_each_layer]: [4, 4, 1]\n",
    "\n",
    "        layer_nin_nout = [nin] + nouts\n",
    "\n",
    "        self.layers = [\n",
    "            Layer(layer_nin_nout[i], layer_nin_nout[i+1], non_linearity =(True if i!=len(nouts)-1 else False))\n",
    "            for i in range(len(nouts))\n",
    "        ]\n",
    "    #end-def \n",
    "\n",
    "    def __call__(self, xs):\n",
    "        # return [layer(xs) for layer in self.layers]\n",
    "        for layer in self.layers:\n",
    "            xs = layer(xs)\n",
    "        #end-for\n",
    "        return xs\n",
    "    #end-def\n",
    "\n",
    "    def parameters(self):\n",
    "        return [parameter for layer in self.layers for parameter in layer.parameters()]\n",
    "    #end-def\n",
    "#end-class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b9bb6b",
   "metadata": {},
   "source": [
    "##### → Training 1: four samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "aaea4ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [\n",
    "    [Value(2.0, label='x1 [sample #1]'),   Value(3.0,  label='x2 [sample #1]'),  Value(-1.0, label='x3 [sample #1]')],\n",
    "    [Value(3.0, label='x1 [sample #2]'),   Value(-1.0, label='x2 [sample #2]'),  Value(0.5,  label='x3 [sample #2]')],\n",
    "    [Value(0.5, label='x1 [sample #3]'),   Value(1.0,  label='x2 [sample #3]'),  Value(1.0,  label='x3 [sample #3]')],\n",
    "    [Value(1.0, label='x1 [sample #4]'),   Value(1.0,  label='x2 [sample #4]'),  Value(-1.0, label='x3 [sample #4]')],\n",
    "]\n",
    "\n",
    "ys = [1.0, -1.0, -1.0, 1.0] #desired outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "7404c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nin = 3   # dimention of X\n",
    "nouts = [4, 4, 1]\n",
    "\n",
    "# nin   [number_of_connections_of_each_neuron, number_of_dimenstions]: 3\n",
    "# nout  [number_of_neurons_of_each_layer]: 5\n",
    "# nouts [neurons_of_each_layer]: [4, 4, 1]\n",
    "\n",
    "model = MLP(nin, nouts)\n",
    "\n",
    "# parameters = model.parameters()\n",
    "# number_of_parameters = len(parameters)\n",
    "# print(number_of_parameters) # 41"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebe1fba",
   "metadata": {},
   "source": [
    "###### `Forward pass:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7dc675ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Neuron' object has no attribute 'non_linearity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[197], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ysp \u001b[38;5;241m=\u001b[39m [model(xs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m X]\n\u001b[1;32m      3\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([(y \u001b[38;5;241m-\u001b[39m yp)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m y, yp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ys, ysp)])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[197], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ysp \u001b[38;5;241m=\u001b[39m [model(xs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m X]\n\u001b[1;32m      3\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([(y \u001b[38;5;241m-\u001b[39m yp)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m y, yp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ys, ysp)])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[193], line 81\u001b[0m, in \u001b[0;36mMLP.__call__\u001b[0;34m(self, xs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, xs):\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# return [layer(xs) for layer in self.layers]\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 81\u001b[0m         xs \u001b[38;5;241m=\u001b[39m layer(xs)\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m#end-for\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xs\n",
      "Cell \u001b[0;32mIn[193], line 51\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, xs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, xs):\n\u001b[0;32m---> 51\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [neuron(xs) \u001b[38;5;28;01mfor\u001b[39;00m neuron \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneurons]\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(outputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[193], line 51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, xs):\n\u001b[0;32m---> 51\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [neuron(xs) \u001b[38;5;28;01mfor\u001b[39;00m neuron \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneurons]\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(outputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[193], line 30\u001b[0m, in \u001b[0;36mNeuron.__call__\u001b[0;34m(self, xs)\u001b[0m\n\u001b[1;32m     27\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([(w\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m w, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights, xs)]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;66;03m# pre-activation\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# a = z.tanh() # passed through activaton function (=non linearity).\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# a.label = 'a (=output for each sample)'\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z\u001b[38;5;241m.\u001b[39mtanh() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnon_linearity \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m z\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Neuron' object has no attribute 'non_linearity'"
     ]
    }
   ],
   "source": [
    "ysp = [model(xs) for xs in X]\n",
    "\n",
    "loss = sum([(y - yp)**2.0 for y, yp in zip(ys, ysp)])\n",
    "print(f'loss: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a449fb92",
   "metadata": {},
   "source": [
    "###### `Backward pass:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63eb728",
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in model.parameters():\n",
    "    parameter.grad = 0.0\n",
    "#end-for\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8872455a",
   "metadata": {},
   "source": [
    "###### `Update parameters:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a93e2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1.0/1000.0\n",
    "\n",
    "for parameter in model.parameters():\n",
    "    parameter.data = parameter.data - (learning_rate * parameter.grad)\n",
    "#end-for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1970de6d",
   "metadata": {},
   "source": [
    "###### `Forward pass`, `Backward pass` and `Update parameters`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b3bd5350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7005 at epoch 0\n",
      "loss: 0.5570 at epoch 50\n",
      "loss: 0.4329 at epoch 100\n",
      "loss: 0.3312 at epoch 150\n",
      "loss: 0.2507 at epoch 200\n",
      "loss: 0.1880 at epoch 250\n",
      "loss: 0.1400 at epoch 300\n",
      "loss: 0.1036 at epoch 350\n"
     ]
    }
   ],
   "source": [
    "number_of_epochs = 350+1\n",
    "learning_rate = 1.0/1000.0\n",
    "\n",
    "\n",
    "def MSE(ysp):\n",
    "    return sum([(y - yp)**2.0 for y, yp in zip(ys, ysp)]) / len(ys)\n",
    "#end-def\n",
    "\n",
    "losses = []\n",
    "for epoch in range(number_of_epochs):\n",
    "    # Forward pass:\n",
    "    ysp = [model(xs) for xs in X]\n",
    "    loss = MSE(ysp)\n",
    "    \n",
    "    # Backward pass:\n",
    "    for parameter in model.parameters():\n",
    "        parameter.grad = 0.0\n",
    "    #end-for\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters:\n",
    "    for parameter in model.parameters():\n",
    "        parameter.data = parameter.data - (learning_rate * parameter.grad)\n",
    "    #end-for\n",
    "\n",
    "    # Visualize:\n",
    "    if epoch%50==0:\n",
    "        print(f'loss: {loss.data:0.4f} at epoch {epoch}')\n",
    "    #end-if/else\n",
    "\n",
    "    losses.append(loss.data)\n",
    "#end-for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ed43f659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def loss_plot(losses):\n",
    "    plt.title('How does loss function change over training steps?', fontsize=12)\n",
    "\n",
    "    plt.plot(losses, color='red', marker='.', linewidth=2.0)\n",
    "    plt.xlabel('Epoch (Training Step)', fontsize=10)\n",
    "    plt.ylabel('MSE Loss', fontsize=10)\n",
    "\n",
    "    plt.savefig(fname='output/Loss_Function_over_Training_Steps.png', dpi=600)\n",
    "    plt.show()\n",
    "#end-def\n",
    "\n",
    "loss_plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ad7509",
   "metadata": {},
   "source": [
    "##### → Training 2: Grok's Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "4c68031c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Val Accuracy: 0.5333\n",
      "Epoch 2, Val Accuracy: 0.5667\n",
      "Epoch 3, Val Accuracy: 0.6333\n",
      "Epoch 4, Val Accuracy: 0.6667\n",
      "Epoch 5, Val Accuracy: 0.6667\n",
      "Epoch 6, Val Accuracy: 0.7000\n",
      "Epoch 7, Val Accuracy: 0.7000\n",
      "Epoch 8, Val Accuracy: 0.7333\n",
      "Epoch 9, Val Accuracy: 0.7333\n",
      "Epoch 10, Val Accuracy: 0.7333\n",
      "Epoch 11, Val Accuracy: 0.7000\n",
      "Epoch 12, Val Accuracy: 0.7000\n",
      "Epoch 13, Val Accuracy: 0.7000\n",
      "Epoch 14, Val Accuracy: 0.7000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[262], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Backpropagate\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m average_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Update parameters\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters():\n",
      "Cell \u001b[0;32mIn[184], line 200\u001b[0m, in \u001b[0;36mValue.backward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m         ordered_topology\u001b[38;5;241m.\u001b[39mappend(node)\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m#end-if/else\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m#end-def\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m build_topology(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(ordered_topology):\n",
      "Cell \u001b[0;32mIn[184], line 194\u001b[0m, in \u001b[0;36mValue.backward.<locals>.build_topology\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# children = node._children\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# child = 0\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# while child<len(children):\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m#     build_topology(children[child])\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m#     child += 1\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# #end-while\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39m_children:\n\u001b[0;32m--> 194\u001b[0m     build_topology(child)\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m#end-for\u001b[39;00m\n\u001b[1;32m    197\u001b[0m ordered_topology\u001b[38;5;241m.\u001b[39mappend(node)\n",
      "Cell \u001b[0;32mIn[184], line 194\u001b[0m, in \u001b[0;36mValue.backward.<locals>.build_topology\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# children = node._children\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# child = 0\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# while child<len(children):\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m#     build_topology(children[child])\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m#     child += 1\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# #end-while\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39m_children:\n\u001b[0;32m--> 194\u001b[0m     build_topology(child)\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m#end-for\u001b[39;00m\n\u001b[1;32m    197\u001b[0m ordered_topology\u001b[38;5;241m.\u001b[39mappend(node)\n",
      "    \u001b[0;31m[... skipping similar frames: Value.backward.<locals>.build_topology at line 194 (38 times)]\u001b[0m\n",
      "Cell \u001b[0;32mIn[184], line 194\u001b[0m, in \u001b[0;36mValue.backward.<locals>.build_topology\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# children = node._children\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# child = 0\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# while child<len(children):\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m#     build_topology(children[child])\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m#     child += 1\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# #end-while\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39m_children:\n\u001b[0;32m--> 194\u001b[0m     build_topology(child)\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m#end-for\u001b[39;00m\n\u001b[1;32m    197\u001b[0m ordered_topology\u001b[38;5;241m.\u001b[39mappend(node)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generate a sample dataset with 1000 samples and 5 features\n",
    "n_samples = 300\n",
    "X = np.random.randn(n_samples, 5)\n",
    "y = np.zeros(n_samples, dtype=int)\n",
    "y[X[:, 0] < -1] = 0  # Class 0 if first feature < -1\n",
    "y[(X[:, 0] >= -1) & (X[:, 0] < 1)] = 1  # Class 1 if -1 <= first feature < 1\n",
    "y[X[:, 0] >= 1] = 2  # Class 2 if first feature >= 1\n",
    "\n",
    "# Split dataset into training (80%), validation (10%), and test (10%) sets\n",
    "indices = np.arange(n_samples)\n",
    "np.random.shuffle(indices)\n",
    "train_size = int(0.8 * n_samples)\n",
    "val_size = int(0.1 * n_samples)\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:train_size + val_size]\n",
    "test_indices = indices[train_size + val_size:]\n",
    "\n",
    "X_train = X[train_indices]\n",
    "y_train = y[train_indices]\n",
    "X_val = X[val_indices]\n",
    "y_val = y[val_indices]\n",
    "X_test = X[test_indices]\n",
    "y_test = y[test_indices]\n",
    "\n",
    "# Initialize the MLP with input size 5, four hidden layers of 8 neurons, and 3 output classes\n",
    "model = MLP(5, [8, 8, 8, 3])\n",
    "\n",
    "# Set training hyperparameters\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "batch_size = 16\n",
    "\n",
    "# Function to compute accuracy on a dataset\n",
    "def compute_accuracy(model, X, y):\n",
    "    correct = 0\n",
    "    for x, true_y in zip(X, y):\n",
    "        x_val = [Value(feature) for feature in x]\n",
    "        logits = model(x_val)\n",
    "        pred = np.argmax([logit.data for logit in logits])\n",
    "        if pred == true_y:\n",
    "            correct += 1\n",
    "    return correct / len(y)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Shuffle training data\n",
    "    train_perm = np.random.permutation(len(X_train))\n",
    "    X_train_shuffled = X_train[train_perm]\n",
    "    y_train_shuffled = y_train[train_perm]\n",
    "    \n",
    "    # Process mini-batches\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        end_i = min(i + batch_size, len(X_train))\n",
    "        batch_X = X_train_shuffled[i:end_i]\n",
    "        batch_y = y_train_shuffled[i:end_i]\n",
    "        \n",
    "        # Compute cross-entropy loss for the batch\n",
    "        total_loss = Value(0.0)\n",
    "        for x, y in zip(batch_X, batch_y):\n",
    "            x_val = [Value(feature) for feature in x]\n",
    "            logits = model(x_val)\n",
    "            exp_logits = [logit.exp() for logit in logits]\n",
    "            sum_exp = Value(0.0)\n",
    "            for el in exp_logits:\n",
    "                sum_exp += el\n",
    "            probs = [el / sum_exp for el in exp_logits]\n",
    "            loss = -probs[y].log()\n",
    "            total_loss += loss\n",
    "        \n",
    "        average_loss = total_loss / len(batch_X)\n",
    "        \n",
    "        # Zero gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Backpropagate\n",
    "        average_loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        for p in model.parameters():\n",
    "            p.data -= learning_rate * p.grad\n",
    "    \n",
    "    # Compute and print validation accuracy\n",
    "    val_accuracy = compute_accuracy(model, X_val, y_val)\n",
    "    print(f\"Epoch {epoch + 1}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_accuracy = compute_accuracy(model, X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "cb012886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in range(1, 20):\n",
    "#     lr = 1.0 - ((0.9*k)/100.0)\n",
    "#     print(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18688d02",
   "metadata": {},
   "source": [
    "##### Karpaty's Assignment on MicroGrad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8d3bd1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Value(data=0.5915, grad=0.0000, label=), Value(data=1.0591, grad=0.0000, label=), Value(data=-0.6549, grad=0.0000, label=)], [Value(data=1.8970, grad=0.0000, label=), Value(data=-1.6331, grad=0.0000, label=), Value(data=0.2792, grad=0.0000, label=)], [Value(data=0.7984, grad=0.0000, label=), Value(data=-1.1234, grad=0.0000, label=), Value(data=0.2001, grad=0.0000, label=)], [Value(data=1.0400, grad=0.0000, label=), Value(data=1.7956, grad=0.0000, label=), Value(data=-1.0599, grad=0.0000, label=)]]\n"
     ]
    }
   ],
   "source": [
    "model = MLP(4, [5, 3])\n",
    "# print(len(model.parameters()))\n",
    "\n",
    "xs = [1.0, 2.0, 3.0]\n",
    "\n",
    "\n",
    "X = [\n",
    "    [1.0, 2.0, 3.0, 1],\n",
    "    [-1.0, 2.0, -3.0, 1],\n",
    "    [1.0, 2.0, -3.0, 1],\n",
    "    [-1.0, 2.0, 3.0, 0],\n",
    "]\n",
    "\n",
    "\n",
    "Y = [\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1],\n",
    "    [0, 0, 1],\n",
    "]\n",
    "\n",
    "Yp = [model(xs) for xs in X]\n",
    "\n",
    "print(Yp)\n",
    "# ysp = [Value(data=0.0), Value(data=3.0), Value(data=-2.0), Value(data=1.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fb676d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "aa7e7e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "V = [[1, 3, 3], [1, 2, 3]]\n",
    "\n",
    "print(len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2f48c6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=2.3000, grad=0.0000, label=)\n"
     ]
    }
   ],
   "source": [
    "def softmax(logits):\n",
    "    # When we have multiples outputs...\n",
    "    elements = [logit.exp() for logit in logits]\n",
    "    SUM = sum(elements)\n",
    "    return [(element/SUM) for element in elements]\n",
    "#end-def\n",
    "\n",
    "def NLL(ys, ps):\n",
    "    return -sum([y*(p+0.00000000001).log() for y, p in zip(ys, ps)])\n",
    "#end-def\n",
    "\n",
    "def categorical_cross_entrorpy(Y, Yp):\n",
    "    losses = []\n",
    "    for ys, ysp in zip(Y, Yp):\n",
    "        ps = softmax(ysp)\n",
    "        losses.append(NLL(ys, ps))\n",
    "    #end-for\n",
    "    return sum(losses)/len(Y)\n",
    "#end-def\n",
    "\n",
    "loss = categorical_cross_entrorpy(Y, Yp)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d41d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7f97abc",
   "metadata": {},
   "source": [
    "##### → Classify Iris Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d9b49",
   "metadata": {},
   "source": [
    "###### Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f988fc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setosa:     [1, 0, 0]\n",
    "# versicolor: [0, 1, 0]\n",
    "# virginica:  [0, 0, 1]\n",
    "\n",
    "Y = [\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0]\n",
    "]\n",
    "\n",
    "# Y\n",
    "\n",
    "X = [\n",
    "    [5.1, 3.5, 1.4, 0.2],\n",
    "    [4.9, 3.0, 1.4, 0.2],\n",
    "    [4.7, 3.2, 1.3, 0.2],\n",
    "    [4.6, 3.1, 1.5, 0.2],\n",
    "    [5.0, 3.6, 1.4, 0.2],\n",
    "    [5.4, 3.9, 1.7, 0.4],\n",
    "    [4.6, 3.4, 1.4, 0.3],\n",
    "    [5.0, 3.4, 1.5, 0.2],\n",
    "    [4.4, 2.9, 1.4, 0.2],\n",
    "    [4.9, 3.1, 1.5, 0.1],\n",
    "    [5.4, 3.7, 1.5, 0.2],\n",
    "    [4.8, 3.4, 1.6, 0.2],\n",
    "    [4.8, 3.0, 1.4, 0.1],\n",
    "    [4.3, 3.0, 1.1, 0.1],\n",
    "    [5.8, 4.0, 1.2, 0.2],\n",
    "    [5.7, 4.4, 1.5, 0.4],\n",
    "    [5.4, 3.9, 1.3, 0.4],\n",
    "    [5.1, 3.5, 1.4, 0.3],\n",
    "    [5.7, 3.8, 1.7, 0.3],\n",
    "    [5.1, 3.8, 1.5, 0.3],\n",
    "    [5.4, 3.4, 1.7, 0.2],\n",
    "    [5.1, 3.7, 1.5, 0.4],\n",
    "    [4.6, 3.6, 1.0, 0.2],\n",
    "    [5.1, 3.3, 1.7, 0.5],\n",
    "    [4.8, 3.4, 1.9, 0.2],\n",
    "    [5.0, 3.0, 1.6, 0.2],\n",
    "    [5.0, 3.4, 1.6, 0.4],\n",
    "    [5.2, 3.5, 1.5, 0.2],\n",
    "    [5.2, 3.4, 1.4, 0.2],\n",
    "    [4.7, 3.2, 1.6, 0.2],\n",
    "    [4.8, 3.1, 1.6, 0.2],\n",
    "    [5.4, 3.4, 1.5, 0.4],\n",
    "    [5.2, 4.1, 1.5, 0.1],\n",
    "    [5.5, 4.2, 1.4, 0.2],\n",
    "    [4.9, 3.1, 1.5, 0.1],\n",
    "    [5.0, 3.2, 1.2, 0.2],\n",
    "    [5.5, 3.5, 1.3, 0.2],\n",
    "    [4.9, 3.1, 1.5, 0.1],\n",
    "    [4.4, 3.0, 1.3, 0.2],\n",
    "    [5.1, 3.4, 1.5, 0.2],\n",
    "    [5.0, 3.5, 1.3, 0.3],\n",
    "    [4.5, 2.3, 1.3, 0.3],\n",
    "    [4.4, 3.2, 1.3, 0.2],\n",
    "    [5.0, 3.5, 1.6, 0.6],\n",
    "    [5.1, 3.8, 1.9, 0.4],\n",
    "    [4.8, 3.0, 1.4, 0.3],\n",
    "    [5.1, 3.8, 1.6, 0.2],\n",
    "    [4.6, 3.2, 1.4, 0.2],\n",
    "    [5.3, 3.7, 1.5, 0.2],\n",
    "    [5.0, 3.3, 1.4, 0.2],\n",
    "    [7.0, 3.2, 4.7, 1.4],\n",
    "    [6.4, 3.2, 4.5, 1.5],\n",
    "    [6.9, 3.1, 4.9, 1.5],\n",
    "    [5.5, 2.3, 4.0, 1.3],\n",
    "    [6.5, 2.8, 4.6, 1.5],\n",
    "    [5.7, 2.8, 4.5, 1.3],\n",
    "    [6.3, 3.3, 4.7, 1.6],\n",
    "    [4.9, 2.4, 3.3, 1.0],\n",
    "    [6.6, 2.9, 4.6, 1.3],\n",
    "    [5.2, 2.7, 3.9, 1.4],\n",
    "    [5.0, 2.0, 3.5, 1.0],\n",
    "    [5.9, 3.0, 4.2, 1.5],\n",
    "    [6.0, 2.2, 4.0, 1.0],\n",
    "    [6.1, 2.9, 4.7, 1.4],\n",
    "    [5.6, 2.9, 3.6, 1.3],\n",
    "    [6.7, 3.1, 4.4, 1.4],\n",
    "    [5.6, 3.0, 4.5, 1.5],\n",
    "    [5.8, 2.7, 4.1, 1.0],\n",
    "    [6.2, 2.2, 4.5, 1.5],\n",
    "    [5.6, 2.5, 3.9, 1.1],\n",
    "    [5.9, 3.2, 4.8, 1.8],\n",
    "    [6.1, 2.8, 4.0, 1.3],\n",
    "    [6.3, 2.5, 4.9, 1.5],\n",
    "    [6.1, 2.8, 4.7, 1.2],\n",
    "    [6.4, 2.9, 4.3, 1.3],\n",
    "    [6.6, 3.0, 4.4, 1.4],\n",
    "    [6.8, 2.8, 4.8, 1.4],\n",
    "    [6.7, 3.0, 5.0, 1.7],\n",
    "    [6.0, 2.9, 4.5, 1.5],\n",
    "    [5.7, 2.6, 3.5, 1.0],\n",
    "    [5.5, 2.4, 3.8, 1.1],\n",
    "    [5.5, 2.4, 3.7, 1.0],\n",
    "    [5.8, 2.7, 3.9, 1.2],\n",
    "    [6.0, 2.7, 5.1, 1.6],\n",
    "    [5.4, 3.0, 4.5, 1.5],\n",
    "    [6.0, 3.4, 4.5, 1.6],\n",
    "    [6.7, 3.1, 4.7, 1.5],\n",
    "    [6.3, 2.3, 4.4, 1.3],\n",
    "    [5.6, 3.0, 4.1, 1.3],\n",
    "    [5.5, 2.5, 4.0, 1.3],\n",
    "    [5.5, 2.6, 4.4, 1.2],\n",
    "    [6.1, 3.0, 4.6, 1.4],\n",
    "    [5.8, 2.6, 4.0, 1.2],\n",
    "    [5.0, 2.3, 3.3, 1.0],\n",
    "    [5.6, 2.7, 4.2, 1.3],\n",
    "    [5.7, 3.0, 4.2, 1.2],\n",
    "    [5.7, 2.9, 4.2, 1.3],\n",
    "    [6.2, 2.9, 4.3, 1.3],\n",
    "    [5.1, 2.5, 3.0, 1.1],\n",
    "    [5.7, 2.8, 4.1, 1.3],\n",
    "    [6.3, 3.3, 6.0, 2.5],\n",
    "    [5.8, 2.7, 5.1, 1.9],\n",
    "    [7.1, 3.0, 5.9, 2.1],\n",
    "    [6.3, 2.9, 5.6, 1.8],\n",
    "    [6.5, 3.0, 5.8, 2.2],\n",
    "    [7.6, 3.0, 6.6, 2.1],\n",
    "    [4.9, 2.5, 4.5, 1.7],\n",
    "    [7.3, 2.9, 6.3, 1.8],\n",
    "    [6.7, 2.5, 5.8, 1.8],\n",
    "    [7.2, 3.6, 6.1, 2.5],\n",
    "    [6.5, 3.2, 5.1, 2.0],\n",
    "    [6.4, 2.7, 5.3, 1.9],\n",
    "    [6.8, 3.0, 5.5, 2.1],\n",
    "    [5.7, 2.5, 5.0, 2.0],\n",
    "    [5.8, 2.8, 5.1, 2.4],\n",
    "    [6.4, 3.2, 5.3, 2.3],\n",
    "    [6.5, 3.0, 5.5, 1.8],\n",
    "    [7.7, 3.8, 6.7, 2.2],\n",
    "    [7.7, 2.6, 6.9, 2.3],\n",
    "    [6.0, 2.2, 5.0, 1.5],\n",
    "    [6.9, 3.2, 5.7, 2.3],\n",
    "    [5.6, 2.8, 4.9, 2.0],\n",
    "    [7.7, 2.8, 6.7, 2.0],\n",
    "    [6.3, 2.7, 4.9, 1.8],\n",
    "    [6.7, 3.3, 5.7, 2.1],\n",
    "    [7.2, 3.2, 6.0, 1.8],\n",
    "    [6.2, 2.8, 4.8, 1.8],\n",
    "    [6.1, 3.0, 4.9, 1.8],\n",
    "    [6.4, 2.8, 5.6, 2.1],\n",
    "    [7.2, 3.0, 5.8, 1.6],\n",
    "    [7.4, 2.8, 6.1, 1.9],\n",
    "    [7.9, 3.8, 6.4, 2.0],\n",
    "    [6.4, 2.8, 5.6, 2.2],\n",
    "    [6.3, 2.8, 5.1, 1.5],\n",
    "    [6.1, 2.6, 5.6, 1.4],\n",
    "    [7.7, 3.0, 6.1, 2.3],\n",
    "    [6.3, 3.4, 5.6, 2.4],\n",
    "    [6.4, 3.1, 5.5, 1.8],\n",
    "    [6.0, 3.0, 4.8, 1.8],\n",
    "    [6.9, 3.1, 5.4, 2.1],\n",
    "    [6.7, 3.1, 5.6, 2.4],\n",
    "    [6.9, 3.1, 5.1, 2.3],\n",
    "    [5.8, 2.7, 5.1, 1.9],\n",
    "    [6.8, 3.2, 5.9, 2.3],\n",
    "    [6.7, 3.3, 5.7, 2.5],\n",
    "    [6.7, 3.0, 5.2, 2.3],\n",
    "    [6.3, 2.5, 5.0, 1.9],\n",
    "    [6.5, 3.0, 5.2, 2.0],\n",
    "    [6.2, 3.4, 5.4, 2.3],\n",
    "    [5.9, 3.0, 5.1, 1.8]\n",
    "]\n",
    "\n",
    "len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088be93f",
   "metadata": {},
   "source": [
    "###### Dataset shuffle and split into train, validation and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "87ef717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X, Y = shuffle(X, Y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "39425890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5e0755cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 150\n",
      "Training set: 104 samples (69.3%)\n",
      "Validation set: 23 samples (15.3%)\n",
      "Test set: 23 samples (15.3%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Step 1: Split into train+val and test\n",
    "X_temp, X_test, Y_temp, Y_test = train_test_split(X, Y, \n",
    "    test_size=test_ratio,\n",
    "    random_state=42,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "\n",
    "val_relative_ratio = val_ratio / (train_ratio + val_ratio)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_temp, Y_temp, test_size=val_relative_ratio,\n",
    "    random_state=42,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Verify the sizes\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Training set: {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Validation set: {len(X_val)} samples ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set: {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e954be",
   "metadata": {},
   "source": [
    "###### NN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2eede613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Value(data=-0.2811, grad=0.0000, label=), Value(data=0.6163, grad=0.0000, label=), Value(data=0.4255, grad=0.0000, label=)], [Value(data=-0.2638, grad=0.0000, label=), Value(data=0.4135, grad=0.0000, label=), Value(data=-0.1347, grad=0.0000, label=)], [Value(data=-0.4619, grad=0.0000, label=), Value(data=1.1021, grad=0.0000, label=), Value(data=0.7289, grad=0.0000, label=)], [Value(data=-0.2874, grad=0.0000, label=), Value(data=0.6459, grad=0.0000, label=), Value(data=0.4245, grad=0.0000, label=)], [Value(data=-0.3132, grad=0.0000, label=), Value(data=0.6667, grad=0.0000, label=), Value(data=0.4781, grad=0.0000, label=)], [Value(data=-0.3167, grad=0.0000, label=), Value(data=0.4443, grad=0.0000, label=), Value(data=-0.0755, grad=0.0000, label=)], [Value(data=-0.2432, grad=0.0000, label=), Value(data=0.5069, grad=0.0000, label=), Value(data=0.3303, grad=0.0000, label=)], [Value(data=-0.3700, grad=0.0000, label=), Value(data=0.8611, grad=0.0000, label=), Value(data=0.5467, grad=0.0000, label=)], [Value(data=-0.3139, grad=0.0000, label=), Value(data=0.6875, grad=0.0000, label=), Value(data=0.4882, grad=0.0000, label=)], [Value(data=-0.2516, grad=0.0000, label=), Value(data=0.5283, grad=0.0000, label=), Value(data=0.3722, grad=0.0000, label=)], [Value(data=-0.3392, grad=0.0000, label=), Value(data=0.7964, grad=0.0000, label=), Value(data=0.4979, grad=0.0000, label=)], [Value(data=-0.2307, grad=0.0000, label=), Value(data=0.3239, grad=0.0000, label=), Value(data=-0.0500, grad=0.0000, label=)], [Value(data=-0.3233, grad=0.0000, label=), Value(data=0.4296, grad=0.0000, label=), Value(data=-0.1051, grad=0.0000, label=)], [Value(data=-0.2174, grad=0.0000, label=), Value(data=0.3190, grad=0.0000, label=), Value(data=-0.0567, grad=0.0000, label=)], [Value(data=-0.1892, grad=0.0000, label=), Value(data=0.3626, grad=0.0000, label=), Value(data=-0.2493, grad=0.0000, label=)], [Value(data=-0.2945, grad=0.0000, label=), Value(data=0.6649, grad=0.0000, label=), Value(data=0.4263, grad=0.0000, label=)], [Value(data=-0.3797, grad=0.0000, label=), Value(data=0.9302, grad=0.0000, label=), Value(data=0.5708, grad=0.0000, label=)], [Value(data=-0.2470, grad=0.0000, label=), Value(data=0.5208, grad=0.0000, label=), Value(data=0.3712, grad=0.0000, label=)], [Value(data=-0.2712, grad=0.0000, label=), Value(data=0.6128, grad=0.0000, label=), Value(data=0.4035, grad=0.0000, label=)], [Value(data=-0.3772, grad=0.0000, label=), Value(data=0.9187, grad=0.0000, label=), Value(data=0.5701, grad=0.0000, label=)], [Value(data=-0.1654, grad=0.0000, label=), Value(data=0.3000, grad=0.0000, label=), Value(data=-0.1142, grad=0.0000, label=)], [Value(data=-0.3174, grad=0.0000, label=), Value(data=0.7459, grad=0.0000, label=), Value(data=0.4683, grad=0.0000, label=)], [Value(data=-0.2255, grad=0.0000, label=), Value(data=0.3791, grad=0.0000, label=), Value(data=-0.1322, grad=0.0000, label=)], [Value(data=-0.3711, grad=0.0000, label=), Value(data=0.8990, grad=0.0000, label=), Value(data=0.5623, grad=0.0000, label=)], [Value(data=-0.3955, grad=0.0000, label=), Value(data=0.9123, grad=0.0000, label=), Value(data=0.5907, grad=0.0000, label=)], [Value(data=-0.3715, grad=0.0000, label=), Value(data=0.8790, grad=0.0000, label=), Value(data=0.5517, grad=0.0000, label=)], [Value(data=-0.3759, grad=0.0000, label=), Value(data=0.8812, grad=0.0000, label=), Value(data=0.5878, grad=0.0000, label=)], [Value(data=-0.3899, grad=0.0000, label=), Value(data=0.9494, grad=0.0000, label=), Value(data=0.5822, grad=0.0000, label=)], [Value(data=-0.2638, grad=0.0000, label=), Value(data=0.3734, grad=0.0000, label=), Value(data=-0.0533, grad=0.0000, label=)], [Value(data=-0.1979, grad=0.0000, label=), Value(data=0.3175, grad=0.0000, label=), Value(data=-0.0660, grad=0.0000, label=)], [Value(data=-0.2078, grad=0.0000, label=), Value(data=0.3568, grad=0.0000, label=), Value(data=-0.2903, grad=0.0000, label=)], [Value(data=-0.2385, grad=0.0000, label=), Value(data=0.4428, grad=0.0000, label=), Value(data=-0.3319, grad=0.0000, label=)], [Value(data=-0.2888, grad=0.0000, label=), Value(data=0.6018, grad=0.0000, label=), Value(data=0.4263, grad=0.0000, label=)], [Value(data=-0.1556, grad=0.0000, label=), Value(data=0.3037, grad=0.0000, label=), Value(data=-0.1615, grad=0.0000, label=)], [Value(data=-0.1630, grad=0.0000, label=), Value(data=0.3007, grad=0.0000, label=), Value(data=-0.1894, grad=0.0000, label=)], [Value(data=-0.3469, grad=0.0000, label=), Value(data=0.8070, grad=0.0000, label=), Value(data=0.5300, grad=0.0000, label=)], [Value(data=-0.2877, grad=0.0000, label=), Value(data=0.6275, grad=0.0000, label=), Value(data=0.4188, grad=0.0000, label=)], [Value(data=-0.2328, grad=0.0000, label=), Value(data=0.3642, grad=0.0000, label=), Value(data=-0.1367, grad=0.0000, label=)], [Value(data=-0.1995, grad=0.0000, label=), Value(data=0.3469, grad=0.0000, label=), Value(data=-0.2100, grad=0.0000, label=)], [Value(data=-0.1432, grad=0.0000, label=), Value(data=0.3207, grad=0.0000, label=), Value(data=-0.3061, grad=0.0000, label=)], [Value(data=-0.3319, grad=0.0000, label=), Value(data=0.8073, grad=0.0000, label=), Value(data=0.4982, grad=0.0000, label=)], [Value(data=-0.2779, grad=0.0000, label=), Value(data=0.6356, grad=0.0000, label=), Value(data=0.3932, grad=0.0000, label=)], [Value(data=-0.3043, grad=0.0000, label=), Value(data=0.6568, grad=0.0000, label=), Value(data=0.4519, grad=0.0000, label=)], [Value(data=-0.2815, grad=0.0000, label=), Value(data=0.4477, grad=0.0000, label=), Value(data=-0.2521, grad=0.0000, label=)], [Value(data=-0.2414, grad=0.0000, label=), Value(data=0.3809, grad=0.0000, label=), Value(data=-0.1677, grad=0.0000, label=)], [Value(data=-0.2353, grad=0.0000, label=), Value(data=0.4837, grad=0.0000, label=), Value(data=0.3549, grad=0.0000, label=)], [Value(data=-0.3167, grad=0.0000, label=), Value(data=0.7222, grad=0.0000, label=), Value(data=0.4815, grad=0.0000, label=)], [Value(data=-0.3406, grad=0.0000, label=), Value(data=0.8103, grad=0.0000, label=), Value(data=0.5096, grad=0.0000, label=)], [Value(data=-0.2895, grad=0.0000, label=), Value(data=0.6079, grad=0.0000, label=), Value(data=0.4296, grad=0.0000, label=)], [Value(data=-0.4055, grad=0.0000, label=), Value(data=0.9880, grad=0.0000, label=), Value(data=0.5961, grad=0.0000, label=)], [Value(data=-0.2586, grad=0.0000, label=), Value(data=0.5715, grad=0.0000, label=), Value(data=0.3778, grad=0.0000, label=)], [Value(data=-0.4255, grad=0.0000, label=), Value(data=1.0036, grad=0.0000, label=), Value(data=0.6597, grad=0.0000, label=)], [Value(data=-0.2747, grad=0.0000, label=), Value(data=0.6403, grad=0.0000, label=), Value(data=0.3989, grad=0.0000, label=)], [Value(data=-0.2320, grad=0.0000, label=), Value(data=0.3645, grad=0.0000, label=), Value(data=-0.1618, grad=0.0000, label=)], [Value(data=-0.4313, grad=0.0000, label=), Value(data=1.0076, grad=0.0000, label=), Value(data=0.6780, grad=0.0000, label=)], [Value(data=-0.2459, grad=0.0000, label=), Value(data=0.5126, grad=0.0000, label=), Value(data=0.3686, grad=0.0000, label=)], [Value(data=-0.2645, grad=0.0000, label=), Value(data=0.3821, grad=0.0000, label=), Value(data=-0.1136, grad=0.0000, label=)], [Value(data=-0.2477, grad=0.0000, label=), Value(data=0.3895, grad=0.0000, label=), Value(data=-0.1885, grad=0.0000, label=)], [Value(data=-0.1346, grad=0.0000, label=), Value(data=0.3340, grad=0.0000, label=), Value(data=-0.2170, grad=0.0000, label=)], [Value(data=-0.2294, grad=0.0000, label=), Value(data=0.4845, grad=0.0000, label=), Value(data=0.3521, grad=0.0000, label=)], [Value(data=-0.3315, grad=0.0000, label=), Value(data=0.7636, grad=0.0000, label=), Value(data=0.5007, grad=0.0000, label=)], [Value(data=-0.1027, grad=0.0000, label=), Value(data=0.2640, grad=0.0000, label=), Value(data=-0.1354, grad=0.0000, label=)], [Value(data=-0.2488, grad=0.0000, label=), Value(data=0.3481, grad=0.0000, label=), Value(data=-0.0015, grad=0.0000, label=)], [Value(data=-0.2568, grad=0.0000, label=), Value(data=0.4082, grad=0.0000, label=), Value(data=-0.0769, grad=0.0000, label=)], [Value(data=-0.2624, grad=0.0000, label=), Value(data=0.5835, grad=0.0000, label=), Value(data=0.3890, grad=0.0000, label=)], [Value(data=-0.2285, grad=0.0000, label=), Value(data=0.3559, grad=0.0000, label=), Value(data=-0.1212, grad=0.0000, label=)], [Value(data=-0.2495, grad=0.0000, label=), Value(data=0.5458, grad=0.0000, label=), Value(data=0.3622, grad=0.0000, label=)], [Value(data=-0.4123, grad=0.0000, label=), Value(data=0.9872, grad=0.0000, label=), Value(data=0.6152, grad=0.0000, label=)], [Value(data=-0.1822, grad=0.0000, label=), Value(data=0.3134, grad=0.0000, label=), Value(data=-0.1480, grad=0.0000, label=)], [Value(data=-0.2738, grad=0.0000, label=), Value(data=0.5828, grad=0.0000, label=), Value(data=0.4060, grad=0.0000, label=)], [Value(data=-0.3386, grad=0.0000, label=), Value(data=0.8273, grad=0.0000, label=), Value(data=0.5112, grad=0.0000, label=)], [Value(data=-0.2151, grad=0.0000, label=), Value(data=0.3904, grad=0.0000, label=), Value(data=-0.3052, grad=0.0000, label=)], [Value(data=-0.3119, grad=0.0000, label=), Value(data=0.7342, grad=0.0000, label=), Value(data=0.4579, grad=0.0000, label=)], [Value(data=-0.3319, grad=0.0000, label=), Value(data=0.8073, grad=0.0000, label=), Value(data=0.4982, grad=0.0000, label=)], [Value(data=-0.2656, grad=0.0000, label=), Value(data=0.5334, grad=0.0000, label=), Value(data=0.4131, grad=0.0000, label=)], [Value(data=-0.2699, grad=0.0000, label=), Value(data=0.6405, grad=0.0000, label=), Value(data=0.3901, grad=0.0000, label=)], [Value(data=-0.3534, grad=0.0000, label=), Value(data=0.8791, grad=0.0000, label=), Value(data=0.5101, grad=0.0000, label=)], [Value(data=-0.2660, grad=0.0000, label=), Value(data=0.5840, grad=0.0000, label=), Value(data=0.4039, grad=0.0000, label=)], [Value(data=-0.2110, grad=0.0000, label=), Value(data=0.3947, grad=0.0000, label=), Value(data=-0.2172, grad=0.0000, label=)], [Value(data=-0.2137, grad=0.0000, label=), Value(data=0.4430, grad=0.0000, label=), Value(data=0.3167, grad=0.0000, label=)], [Value(data=-0.3527, grad=0.0000, label=), Value(data=0.8303, grad=0.0000, label=), Value(data=0.5367, grad=0.0000, label=)], [Value(data=-0.2418, grad=0.0000, label=), Value(data=0.3607, grad=0.0000, label=), Value(data=-0.1144, grad=0.0000, label=)], [Value(data=-0.2911, grad=0.0000, label=), Value(data=0.3918, grad=0.0000, label=), Value(data=-0.1001, grad=0.0000, label=)], [Value(data=-0.2445, grad=0.0000, label=), Value(data=0.5151, grad=0.0000, label=), Value(data=0.3686, grad=0.0000, label=)], [Value(data=-0.3290, grad=0.0000, label=), Value(data=0.7374, grad=0.0000, label=), Value(data=0.4932, grad=0.0000, label=)], [Value(data=-0.2174, grad=0.0000, label=), Value(data=0.3190, grad=0.0000, label=), Value(data=-0.0567, grad=0.0000, label=)], [Value(data=-0.3589, grad=0.0000, label=), Value(data=0.8997, grad=0.0000, label=), Value(data=0.5291, grad=0.0000, label=)], [Value(data=-0.2100, grad=0.0000, label=), Value(data=0.3429, grad=0.0000, label=), Value(data=-0.1376, grad=0.0000, label=)], [Value(data=-0.2444, grad=0.0000, label=), Value(data=0.4240, grad=0.0000, label=), Value(data=-0.1673, grad=0.0000, label=)], [Value(data=-0.3033, grad=0.0000, label=), Value(data=0.7224, grad=0.0000, label=), Value(data=0.4378, grad=0.0000, label=)], [Value(data=-0.2226, grad=0.0000, label=), Value(data=0.4311, grad=0.0000, label=), Value(data=0.2759, grad=0.0000, label=)], [Value(data=-0.3860, grad=0.0000, label=), Value(data=0.9257, grad=0.0000, label=), Value(data=0.5747, grad=0.0000, label=)], [Value(data=-0.3186, grad=0.0000, label=), Value(data=0.7481, grad=0.0000, label=), Value(data=0.4838, grad=0.0000, label=)], [Value(data=-0.3280, grad=0.0000, label=), Value(data=0.7735, grad=0.0000, label=), Value(data=0.5104, grad=0.0000, label=)], [Value(data=-0.4241, grad=0.0000, label=), Value(data=0.9840, grad=0.0000, label=), Value(data=0.6498, grad=0.0000, label=)], [Value(data=-0.2598, grad=0.0000, label=), Value(data=0.5720, grad=0.0000, label=), Value(data=0.3883, grad=0.0000, label=)], [Value(data=-0.1877, grad=0.0000, label=), Value(data=0.3013, grad=0.0000, label=), Value(data=-0.0852, grad=0.0000, label=)], [Value(data=-0.1915, grad=0.0000, label=), Value(data=0.2987, grad=0.0000, label=), Value(data=-0.1579, grad=0.0000, label=)], [Value(data=-0.3249, grad=0.0000, label=), Value(data=0.7466, grad=0.0000, label=), Value(data=0.5092, grad=0.0000, label=)], [Value(data=-0.3726, grad=0.0000, label=), Value(data=0.8624, grad=0.0000, label=), Value(data=0.5672, grad=0.0000, label=)], [Value(data=-0.1787, grad=0.0000, label=), Value(data=0.3048, grad=0.0000, label=), Value(data=-0.1074, grad=0.0000, label=)], [Value(data=-0.2485, grad=0.0000, label=), Value(data=0.3892, grad=0.0000, label=), Value(data=-0.1634, grad=0.0000, label=)], [Value(data=-0.1912, grad=0.0000, label=), Value(data=0.3100, grad=0.0000, label=), Value(data=-0.1257, grad=0.0000, label=)], [Value(data=-0.3197, grad=0.0000, label=), Value(data=0.7166, grad=0.0000, label=), Value(data=0.4930, grad=0.0000, label=)]]\n"
     ]
    }
   ],
   "source": [
    "model = MLP(4, [8, 3])\n",
    "\n",
    "Yp = [model(xs) for xs in X_train]\n",
    "\n",
    "print(Yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4d21e045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6920adc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=0.7493, grad=0.0000, label=)\n"
     ]
    }
   ],
   "source": [
    "def softmax(logits):\n",
    "    # When we have multiples outputs...\n",
    "    elements = [logit.exp() for logit in logits]\n",
    "    SUM = sum(elements)\n",
    "    return [(element/SUM) for element in elements]\n",
    "#end-def\n",
    "\n",
    "def NLL(ys, ps):\n",
    "    return -sum([y*(p+0.00000000001).log() for y, p in zip(ys, ps)])\n",
    "#end-def\n",
    "\n",
    "def categorical_cross_entrorpy(Y, Yp):\n",
    "    losses = []\n",
    "    for ys, ysp in zip(Y, Yp):\n",
    "        ps = softmax(ysp)\n",
    "        losses.append(NLL(ys, ps))\n",
    "    #end-for\n",
    "    return sum(losses)/len(Y)\n",
    "#end-def\n",
    "\n",
    "loss = categorical_cross_entrorpy(Y, Yp)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1ae18022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 loss: 0.749293088882063\n",
      "epoch:1 loss: 0.7386442367364248\n",
      "epoch:2 loss: 0.7282757033439042\n",
      "epoch:3 loss: 0.7183439018732669\n",
      "epoch:4 loss: 0.7091281464500664\n",
      "epoch:5 loss: 0.7002574043051095\n",
      "epoch:6 loss: 0.6917236220114495\n",
      "epoch:7 loss: 0.6838393529146262\n",
      "epoch:8 loss: 0.6770185259449764\n",
      "epoch:9 loss: 0.6708472299600239\n",
      "epoch:10 loss: 0.665428919516581\n",
      "epoch:11 loss: 0.6604870772408908\n",
      "epoch:12 loss: 0.6559582782996379\n",
      "epoch:13 loss: 0.6519225120246145\n",
      "epoch:14 loss: 0.6482884307607373\n",
      "epoch:15 loss: 0.6448233024096461\n",
      "epoch:16 loss: 0.6415467426095938\n",
      "epoch:17 loss: 0.6383854338796973\n",
      "epoch:18 loss: 0.6353343269285442\n",
      "epoch:19 loss: 0.6323712800535445\n",
      "epoch:20 loss: 0.6296036363414245\n",
      "epoch:21 loss: 0.6269164980600521\n",
      "epoch:22 loss: 0.6243431158666746\n",
      "epoch:23 loss: 0.6218561978948313\n",
      "epoch:24 loss: 0.6194183850441283\n",
      "epoch:25 loss: 0.6170340783654509\n",
      "epoch:26 loss: 0.6147107008223801\n",
      "epoch:27 loss: 0.6124299738940765\n",
      "epoch:28 loss: 0.610217354426888\n",
      "epoch:29 loss: 0.6080676122354965\n",
      "epoch:30 loss: 0.6059404762887994\n",
      "epoch:31 loss: 0.6038530476195892\n",
      "epoch:32 loss: 0.6018281865317073\n",
      "epoch:33 loss: 0.599843326421909\n",
      "epoch:34 loss: 0.5979004417825625\n",
      "epoch:35 loss: 0.5959865995477228\n",
      "epoch:36 loss: 0.594131773174207\n",
      "epoch:37 loss: 0.5923038290815331\n",
      "epoch:38 loss: 0.5905008101341095\n",
      "epoch:39 loss: 0.588738958099289\n",
      "epoch:40 loss: 0.5869921650364743\n",
      "epoch:41 loss: 0.585283557797065\n",
      "epoch:42 loss: 0.5836092051927096\n",
      "epoch:43 loss: 0.5819811277208087\n",
      "epoch:44 loss: 0.580382727824651\n",
      "epoch:45 loss: 0.5787970552700714\n",
      "epoch:46 loss: 0.5772299632229161\n",
      "epoch:47 loss: 0.5756711718746284\n",
      "epoch:48 loss: 0.5741165913032149\n",
      "epoch:49 loss: 0.572569852417098\n",
      "epoch:50 loss: 0.5710360030981013\n",
      "epoch:51 loss: 0.569514978465042\n",
      "epoch:52 loss: 0.5680024208308811\n",
      "epoch:53 loss: 0.5665021118206925\n",
      "epoch:54 loss: 0.5650236718732106\n",
      "epoch:55 loss: 0.5635619923563513\n",
      "epoch:56 loss: 0.5621075748465874\n",
      "epoch:57 loss: 0.5606576773518547\n",
      "epoch:58 loss: 0.55922027676002\n",
      "epoch:59 loss: 0.5577881739433894\n",
      "epoch:60 loss: 0.5563623132774439\n",
      "epoch:61 loss: 0.5549406116262575\n",
      "epoch:62 loss: 0.5535252575226152\n",
      "epoch:63 loss: 0.5521128611549211\n",
      "epoch:64 loss: 0.5507034764235514\n",
      "epoch:65 loss: 0.5492971580984376\n",
      "epoch:66 loss: 0.5478939616795544\n",
      "epoch:67 loss: 0.5464939432651446\n",
      "epoch:68 loss: 0.5450971594273741\n",
      "epoch:69 loss: 0.5437036670951435\n",
      "epoch:70 loss: 0.5423135234437624\n",
      "epoch:71 loss: 0.540926785791211\n",
      "epoch:72 loss: 0.5395435115007063\n",
      "epoch:73 loss: 0.5381643354503642\n",
      "epoch:74 loss: 0.5367906916004369\n",
      "epoch:75 loss: 0.5354208327874225\n",
      "epoch:76 loss: 0.5340558717698082\n",
      "epoch:77 loss: 0.5326971355753676\n",
      "epoch:78 loss: 0.5313420726989307\n",
      "epoch:79 loss: 0.5299907399512551\n",
      "epoch:80 loss: 0.5286458091909606\n",
      "epoch:81 loss: 0.5273072859963124\n",
      "epoch:82 loss: 0.5259732637024563\n",
      "epoch:83 loss: 0.5246439793191615\n",
      "epoch:84 loss: 0.523318570205192\n",
      "epoch:85 loss: 0.5219979581770129\n",
      "epoch:86 loss: 0.5206818396681726\n",
      "epoch:87 loss: 0.5193697299408438\n",
      "epoch:88 loss: 0.5180616781835619\n",
      "epoch:89 loss: 0.5167577331433436\n",
      "epoch:90 loss: 0.5154579430644923\n",
      "epoch:91 loss: 0.5141623556313522\n",
      "epoch:92 loss: 0.5128710179149006\n",
      "epoch:93 loss: 0.5115839763230265\n",
      "epoch:94 loss: 0.5103012765543689\n",
      "epoch:95 loss: 0.5090229635555732\n",
      "epoch:96 loss: 0.5077490814818313\n",
      "epoch:97 loss: 0.50647967366057\n",
      "epoch:98 loss: 0.5052147825581518\n",
      "epoch:99 loss: 0.5039544497494564\n",
      "epoch:100 loss: 0.502698715890211\n",
      "epoch:101 loss: 0.5014476206919461\n",
      "epoch:102 loss: 0.5002012028994415\n",
      "epoch:103 loss: 0.49896003369133424\n",
      "epoch:104 loss: 0.4977239674912674\n",
      "epoch:105 loss: 0.4964927952924493\n",
      "epoch:106 loss: 0.4952663617471301\n",
      "epoch:107 loss: 0.49404468703338084\n",
      "epoch:108 loss: 0.49282788176265885\n",
      "epoch:109 loss: 0.49161607343585845\n",
      "epoch:110 loss: 0.49040917678574764\n",
      "epoch:111 loss: 0.48920715083652866\n",
      "epoch:112 loss: 0.48801011592091803\n",
      "epoch:113 loss: 0.4868180995111064\n",
      "epoch:114 loss: 0.4856312783314258\n",
      "epoch:115 loss: 0.4844493670166991\n",
      "epoch:116 loss: 0.4832725435503806\n",
      "epoch:117 loss: 0.4821008386937555\n",
      "epoch:118 loss: 0.48093427445474846\n",
      "epoch:119 loss: 0.4797737559253917\n",
      "epoch:120 loss: 0.47862006888630537\n",
      "epoch:121 loss: 0.4774714976157886\n",
      "epoch:122 loss: 0.4763281073264562\n",
      "epoch:123 loss: 0.4751899143282608\n",
      "epoch:124 loss: 0.4740569340324138\n",
      "epoch:125 loss: 0.4729292525374344\n",
      "epoch:126 loss: 0.47180680174562445\n",
      "epoch:127 loss: 0.47068954149944275\n",
      "epoch:128 loss: 0.46957754636598276\n",
      "epoch:129 loss: 0.4684708272701244\n",
      "epoch:130 loss: 0.4673694215075406\n",
      "epoch:131 loss: 0.4662733928282044\n",
      "epoch:132 loss: 0.46518255382484003\n",
      "epoch:133 loss: 0.46409702561209604\n",
      "epoch:134 loss: 0.46301681458137517\n",
      "epoch:135 loss: 0.4619419378306104\n",
      "epoch:136 loss: 0.4608724984345612\n",
      "epoch:137 loss: 0.4598082620561937\n",
      "epoch:138 loss: 0.4587493600492038\n",
      "epoch:139 loss: 0.45769579440554475\n",
      "epoch:140 loss: 0.4566475662669961\n",
      "epoch:141 loss: 0.4556047930760635\n",
      "epoch:142 loss: 0.45456724421631317\n",
      "epoch:143 loss: 0.4535354141807182\n",
      "epoch:144 loss: 0.4525092147671033\n",
      "epoch:145 loss: 0.45148833215233075\n",
      "epoch:146 loss: 0.4504728249903633\n",
      "epoch:147 loss: 0.4494626141840822\n",
      "epoch:148 loss: 0.44845765007375826\n",
      "epoch:149 loss: 0.44745798519817975\n",
      "epoch:150 loss: 0.44646361307835286\n",
      "epoch:151 loss: 0.44547452653561503\n",
      "epoch:152 loss: 0.44449079400184877\n",
      "epoch:153 loss: 0.44351227417449673\n",
      "epoch:154 loss: 0.4425389866074799\n",
      "epoch:155 loss: 0.44157095013496117\n",
      "epoch:156 loss: 0.4406081542375941\n",
      "epoch:157 loss: 0.4396505877873935\n",
      "epoch:158 loss: 0.4386982634384702\n",
      "epoch:159 loss: 0.43775117733078384\n",
      "epoch:160 loss: 0.43680921908909626\n",
      "epoch:161 loss: 0.4358724409455467\n",
      "epoch:162 loss: 0.43494082887223073\n",
      "epoch:163 loss: 0.43401436832241075\n",
      "epoch:164 loss: 0.4330930442440914\n",
      "epoch:165 loss: 0.43217684109351145\n",
      "epoch:166 loss: 0.43126578445744174\n",
      "epoch:167 loss: 0.4303597942589274\n",
      "epoch:168 loss: 0.42945884958599295\n",
      "epoch:169 loss: 0.42856295992755994\n",
      "epoch:170 loss: 0.4276721074077546\n",
      "epoch:171 loss: 0.4267862737433717\n",
      "epoch:172 loss: 0.4259054402562046\n",
      "epoch:173 loss: 0.42502958788527817\n",
      "epoch:174 loss: 0.42415876822370474\n",
      "epoch:175 loss: 0.423293151237872\n",
      "epoch:176 loss: 0.4224324735399884\n",
      "epoch:177 loss: 0.4215766741052986\n",
      "epoch:178 loss: 0.4207257270172832\n",
      "epoch:179 loss: 0.4198796304455108\n",
      "epoch:180 loss: 0.41903836313117754\n",
      "epoch:181 loss: 0.41820190352388303\n",
      "epoch:182 loss: 0.4173702297927688\n",
      "epoch:183 loss: 0.41654331983750853\n",
      "epoch:184 loss: 0.41572115129914816\n",
      "epoch:185 loss: 0.41490370157079437\n",
      "epoch:186 loss: 0.41409094780814604\n",
      "epoch:187 loss: 0.4132828669398653\n",
      "epoch:188 loss: 0.4124794356777894\n",
      "epoch:189 loss: 0.411680630526978\n",
      "epoch:190 loss: 0.410886452546304\n",
      "epoch:191 loss: 0.4100968324011584\n",
      "epoch:192 loss: 0.4093117606200499\n",
      "epoch:193 loss: 0.4085312196523558\n",
      "epoch:194 loss: 0.4077551850650687\n",
      "epoch:195 loss: 0.4069836322793665\n",
      "epoch:196 loss: 0.40621653657910556\n",
      "epoch:197 loss: 0.4054540307554375\n",
      "epoch:198 loss: 0.4046960833002162\n",
      "epoch:199 loss: 0.40394251217467414\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "lr = 1e-2\n",
    "\n",
    "losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    # Forward pass\n",
    "    Yp = [model(xs) for xs in X_train]\n",
    "    loss = categorical_cross_entrorpy(Y, Yp)\n",
    "\n",
    "    # Backward pass:\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Update:\n",
    "    for parameter in model.parameters():\n",
    "        parameter.data -= lr * parameter.grad\n",
    "    #end-for\n",
    "\n",
    "    print(f'epoch:{epoch} loss: {loss.data}')\n",
    "    losses.append(loss.data)\n",
    "#end-for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "86a95e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def loss_plot(losses):\n",
    "    plt.title('How does loss function change over training steps?', fontsize=12)\n",
    "\n",
    "    plt.plot(losses, color='red', marker='.', linewidth=2.0)\n",
    "    plt.xlabel('Epoch (Training Step)', fontsize=10)\n",
    "    plt.ylabel('MSE Loss', fontsize=10)\n",
    "\n",
    "    plt.savefig(fname='output/Loss_Function_over_Training_Steps.png', dpi=600)\n",
    "    plt.show()\n",
    "#end-def\n",
    "\n",
    "loss_plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c5d294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
